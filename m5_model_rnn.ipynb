{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import optimizers\n",
    "pd.set_option('display.max_columns', None)\n",
    "print('available GPU devices:', len(os.environ['CUDA_VISIBLE_DEVICES']), \n",
    "      '| device num:', os.environ['CUDA_VISIBLE_DEVICES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data'\n",
    "MODELS_DIR = './models'\n",
    "MODEL_VER = 'v0'\n",
    "CUT_DATE = '2015-07-24'\n",
    "END_DATE = '2016-04-24'\n",
    "print(datetime.strptime(END_DATE, '%Y-%m-%d'))\n",
    "LOOK_BACK = 2 * 28\n",
    "LOOK_FWD = 28\n",
    "BATCH_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CALENDAR_DTYPES = {\n",
    "    'date':             'str',\n",
    "    'wm_yr_wk':         'int16', \n",
    "    'weekday':          'object',\n",
    "    'wday':             'int16', \n",
    "    'month':            'int16', \n",
    "    'year':             'int16', \n",
    "    'd':                'object',\n",
    "    'event_name_1':     'object',\n",
    "    'event_type_1':     'object',\n",
    "    'event_name_2':     'object',\n",
    "    'event_type_2':     'object',\n",
    "    'snap_CA':          'int16', \n",
    "    'snap_TX':          'int16', \n",
    "    'snap_WI':          'int16'\n",
    "}\n",
    "PARSE_DATES = ['date']\n",
    "SPRICES_DTYPES = {\n",
    "    'store_id':    'object', \n",
    "    'item_id':     'object', \n",
    "    'wm_yr_wk':    'int16',  \n",
    "    'sell_price':  'float32'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df():\n",
    "    strain = pd.read_csv('{}/sales_train_validation.csv'.format(DATA_DIR))\n",
    "    print('read train:', strain.shape)\n",
    "    cat_cols = ['id', 'item_id', 'dept_id','store_id', 'cat_id', 'state_id']\n",
    "    last_day = int(strain.columns[-1].replace('d_', ''))\n",
    "    print('last day is:', last_day)\n",
    "    strain = pd.melt(\n",
    "        strain,\n",
    "        id_vars = cat_cols,\n",
    "        value_vars = [col for col in strain.columns if col.startswith('d_')],\n",
    "        var_name = 'd',\n",
    "        value_name = 'sales'\n",
    "    )\n",
    "    print('melted train:', strain.shape)\n",
    "    calendar = pd.read_csv('{}/calendar.csv'.format(DATA_DIR), dtype=CALENDAR_DTYPES, parse_dates=PARSE_DATES)\n",
    "    print('read calendar:', calendar.shape)\n",
    "    strain = strain.merge(calendar, on='d', copy=False)\n",
    "    print('calendar merge done:', strain.shape)\n",
    "    sprices = pd.read_csv('{}/sell_prices.csv'.format(DATA_DIR), dtype=SPRICES_DTYPES)\n",
    "    print('read prices:', sprices.shape)\n",
    "    strain = strain.merge(\n",
    "        sprices, \n",
    "        on=['store_id', 'item_id', 'wm_yr_wk'], \n",
    "        how='left'\n",
    "    )\n",
    "    print('prices merge done:', strain.shape)\n",
    "    print('begin train date:', strain['date'].min())\n",
    "    print('end train date:', strain['date'].max())\n",
    "    strain = strain.loc[strain['date'] >= CUT_DATE]\n",
    "    print('date cut train:', strain.shape)\n",
    "    print('cut train date:', strain['date'].min())\n",
    "    print('end train date:', strain['date'].max())\n",
    "    date_features = {\n",
    "        'week_num': 'weekofyear',\n",
    "        'quarter': 'quarter',\n",
    "        'mday': 'day'\n",
    "    }\n",
    "    for date_feat_name, date_feat_func in date_features.items():\n",
    "        strain[date_feat_name] = getattr(strain['date'].dt, date_feat_func).astype('int16')\n",
    "    print('date features done')\n",
    "    strain['d'] = strain['d'].apply(lambda x: int(x.replace('d_', '')))  \n",
    "    drop_cols = ['date', 'wm_yr_wk', 'weekday']\n",
    "    strain.drop(columns=drop_cols, inplace=True)\n",
    "    strain.sort_values(by=['id', 'd'], inplace=True)\n",
    "    print('trash cols deleted, sorted')\n",
    "    strain['d_'] = strain['d']\n",
    "    print('out dataframe:', strain.shape)\n",
    "    return strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummies(strain, cols_dummy):\n",
    "    print('got shape for dummies:', strain.shape)\n",
    "    strain_dummies = pd.get_dummies(\n",
    "        strain[cols_dummy],\n",
    "        drop_first=False,\n",
    "        dummy_na=True\n",
    "    )\n",
    "    strain.drop(columns=cols_dummy, inplace=True)\n",
    "    strain = pd.concat([strain, strain_dummies], axis=1)\n",
    "    print('out shape for dummies:', strain.shape)\n",
    "    return strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "strain = get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_ids = np.random.choice(strain.id.unique(), 500)\n",
    "list_ids = strain.id.unique()[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain = strain[strain.id.isin(list_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_name = np.random.choice(strain.id.unique())\n",
    "id_sales = strain[strain.id == id_name]['sales']\n",
    "print('from', strain['d'].min(), 'to', strain['d'].max()) \n",
    "plt.figure(figsize=(18, 4))\n",
    "id_sales.plot(label='sales')\n",
    "plt.title(id_name)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['d', 'sales', 'wday', 'month', 'year', \n",
    "            'snap_CA', 'snap_TX', 'snap_WI', \n",
    "            'sell_price', 'week_num', 'quarter', 'mday']\n",
    "SCALER = MinMaxScaler()\n",
    "strain[num_cols] = SCALER.fit_transform(strain[num_cols])\n",
    "print('min-max scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sval = strain[strain.d_ >= (1913 - LOOK_BACK - LOOK_FWD)]\n",
    "print('val | start:', sval.d_.min(), \n",
    "      'end:', sval.d_.max(),\n",
    "      'duration:', sval.d_.max() - sval.d_.min(), \n",
    "      'deep:', LOOK_BACK + LOOK_FWD)\n",
    "strain = strain[strain.d_ <= (1913 - LOOK_FWD)]\n",
    "print('train | start:', strain.d_.min(), \n",
    "      'end:', strain.d_.max(),\n",
    "      'duration:', strain.d_.max() - strain.d_.min(), \n",
    "      'deep:', LOOK_BACK + LOOK_FWD)\n",
    "event_cols = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
    "sdummies_id = strain.drop(columns=num_cols + event_cols + ['d_'])\n",
    "sdummies_id.drop_duplicates(inplace=True)\n",
    "print('dummies df done:', sdummies_id.shape)\n",
    "for col in sdummies_id.columns:\n",
    "    print('dummies:', col, sdummies_id[col].unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cols_dummy = ['item_id', 'dept_id', 'store_id', 'cat_id', 'state_id']\n",
    "cols_features = ['d', 'wday', 'month', 'year', \n",
    "                 'snap_CA', 'snap_TX', 'snap_WI', \n",
    "                 'sell_price', 'week_num', 'quarter', 'mday']\n",
    "sdummies_id = get_dummies(sdummies_id, cols_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_batch(df, dummies, col_id, col_look, look_back, look_fwd, cols_features):\n",
    "    X, y = [], [] \n",
    "    for idx in list(df['id'].unique()):\n",
    "        for i in range(len(df.loc[df[col_id] == idx, col_look]) - look_back - look_fwd):\n",
    "            temp_X = []\n",
    "            temp_X.append(df.loc[df[col_id] == idx, col_look][i : i + look_back])\n",
    "            for col in cols_features:\n",
    "                temp_X.append(df.loc[df[col_id] == idx, col][i + look_fwd : i + look_back + look_fwd])\n",
    "            temp_D = np.array([dummies.loc[dummies[col_id] == idx].values[0][1:]] * look_back).T\n",
    "            temp_X = np.vstack((temp_X, temp_D))\n",
    "            X.append(temp_X)\n",
    "            y.append(df.loc[df[col_id] == idx, col_look][i + look_back : i + look_back + look_fwd])\n",
    "        #print(idx, np.array(X).shape, np.array(y).shape)\n",
    "    X = [x.T for x in np.array(X)] # to feed LSTM with shape as [samples, time steps, features]\n",
    "    #print(np.array(X).shape, np.array(y).shape)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SeqGenerator(df, dummies, col_id, col_look, look_back, look_fwd, cols_features, batch_size):\n",
    "    while True:\n",
    "        for i in range(len(df) // batch_size):\n",
    "            if (i + 1) * batch_size > len(df):\n",
    "                #print('-->', i)\n",
    "                yield get_sequence_batch(\n",
    "                    df[i * batch_size:], \n",
    "                    dummies,\n",
    "                    col_id, \n",
    "                    col_look, \n",
    "                    look_back, \n",
    "                    look_fwd, \n",
    "                    cols_features\n",
    "                )\n",
    "            else:\n",
    "                #print('==>', i)\n",
    "                yield get_sequence_batch(\n",
    "                    df[i * batch_size : (i + 1) * batch_size], \n",
    "                    dummies,\n",
    "                    col_id, \n",
    "                    col_look, \n",
    "                    look_back, \n",
    "                    look_fwd, \n",
    "                    cols_features\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X, y = next(\n",
    "    SeqGenerator(\n",
    "        df=strain, \n",
    "        dummies=sdummies_id, \n",
    "        col_id='id', \n",
    "        col_look='sales', \n",
    "        look_back=LOOK_BACK, \n",
    "        look_fwd=LOOK_FWD, \n",
    "        cols_features=cols_features, \n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    ")\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('batches in train:', len(strain) // BATCH_SIZE + 1)\n",
    "print('batches in val:', len(sval) // BATCH_SIZE + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = sdummies_id.shape[1] + len(num_cols) - 1 \n",
    "model = Sequential()\n",
    "model.add(LSTM(units=512, input_shape=(LOOK_BACK, n_features), return_sequences=True))\n",
    "model.add(Dropout(.4))\n",
    "model.add(LSTM(units=512))\n",
    "model.add(Dropout(.4))\n",
    "model.add(Dense(LOOK_FWD))\n",
    "model.add(Activation('linear'))\n",
    "adam = optimizers.Adam(lr=.001, clipvalue=.5, clipnorm=1)\n",
    "model.compile(loss='mse', optimizer=adam)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_file = '{}/model_{}.h5'.format(MODELS_DIR, MODEL_VER)\n",
    "modelsaver = ModelCheckpoint(\n",
    "    model_file, \n",
    "    monitor='val_loss', \n",
    "    verbose=1, \n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "history = model.fit_generator(\n",
    "    SeqGenerator(\n",
    "        df=strain, \n",
    "        dummies=sdummies_id, \n",
    "        col_id='id', \n",
    "        col_look='sales', \n",
    "        look_back=LOOK_BACK, \n",
    "        look_fwd=LOOK_FWD, \n",
    "        cols_features=cols_features, \n",
    "        batch_size=BATCH_SIZE\n",
    "    ),\n",
    "    steps_per_epoch=len(strain) // BATCH_SIZE + 1,\n",
    "    validation_data=SeqGenerator(\n",
    "        df=sval, \n",
    "        dummies=sdummies_id, \n",
    "        col_id='id', \n",
    "        col_look='sales', \n",
    "        look_back=LOOK_BACK, \n",
    "        look_fwd=LOOK_FWD, \n",
    "        cols_features=cols_features, \n",
    "        batch_size=BATCH_SIZE\n",
    "    ),\n",
    "    validation_steps=len(sval) // BATCH_SIZE + 1,\n",
    "    epochs=100,\n",
    "    callbacks=[earlystopper, modelsaver],\n",
    "    verbose=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = '{}/model_{}.h5'.format(MODELS_DIR, MODEL_VER)\n",
    "model = load_model(model_file)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = next(\n",
    "    SeqGenerator(\n",
    "        df=sval, \n",
    "        dummies=sdummies_id, \n",
    "        col_id='id', \n",
    "        col_look='sales', \n",
    "        look_back=LOOK_BACK, \n",
    "        look_fwd=LOOK_FWD, \n",
    "        cols_features=num_cols, \n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    ")\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_predict(df, pred_len, dummies, col_id, col_look, look_back, look_fwd, cols_features):\n",
    "    X, temp_X = [], []\n",
    "    i_end = len(df) - pred_len - look_back - look_fwd - 1\n",
    "    temp_X.append(df[col_look][i_end : i_end + look_back])\n",
    "    for col in cols_features:\n",
    "        temp_X.append(df[col][i_end + look_fwd : i_end + look_back + look_fwd])\n",
    "    temp_D = np.array([dummies.loc[dummies[col_id] == df.id.values[0]].values[0][1:]] * look_back).T\n",
    "    temp_X = np.vstack((temp_X, temp_D))\n",
    "    X.append(temp_X)\n",
    "    X = [x.T for x in np.array(X)] # to feed LSTM with shape as [samples, time steps, features]\n",
    "    return np.array(X)\n",
    "def upscale(series):\n",
    "    return SCALER.inverse_transform(np.repeat([series], 12, axis=0).T)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 18))\n",
    "for i in range(10):\n",
    "    pred_id = np.random.choice(strain.id.unique())\n",
    "    X_pred = get_sequence_predict(\n",
    "        df=strain[strain.id == pred_id], \n",
    "        pred_len = 0,\n",
    "        dummies=sdummies_id, \n",
    "        col_id='id', \n",
    "        col_look='sales', \n",
    "        look_back=LOOK_BACK, \n",
    "        look_fwd=LOOK_FWD, \n",
    "        cols_features=cols_features\n",
    "    )\n",
    "    preds = model.predict(X_pred)\n",
    "    plt.subplot(5, 2, i + 1)\n",
    "    plt.plot(sval[sval.id == pred_id]['d_'].values[-LOOK_FWD :],\n",
    "             upscale(preds[0]), \n",
    "             label='preds')\n",
    "    plt.plot(sval[sval.id == pred_id]['d_'].values[-LOOK_FWD:], \n",
    "             upscale(sval[sval.id == pred_id]['sales'].values[-LOOK_FWD :]), \n",
    "             label='true')\n",
    "    plt.plot(strain[strain.id == pred_id]['d_'].values[-2 * LOOK_BACK :],\n",
    "             upscale(strain[strain.id == pred_id]['sales'].values[-2 * LOOK_BACK :]),\n",
    "             label='train')\n",
    "    plt.title(pred_id)\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "spred = get_df(is_train=False, backward_lags=LOOK_BACK)\n",
    "spred[num_cols] = SCALER.transform(spred[num_cols])\n",
    "print('min-max scaled')\n",
    "#spred.drop(columns=['d_'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('len per one id:', len(spred[(spred.id == 'FOODS_1_001_CA_1_validation')]))\n",
    "print('unique ids:', len(spred.id.unique()))\n",
    "print('len forward:', len(spred[(spred.id == 'FOODS_1_001_CA_1_validation') & (spred.d_ > 1913)]))\n",
    "print('min max day:', spred.d_.min(), spred.d_.max())\n",
    "spred[spred.d_ >= 1913].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred_id in tqdm(spred.id.unique()):\n",
    "    X_pred = get_sequence_predict(\n",
    "        df=spred[spred.id == pred_id], \n",
    "        pred_len = 28,\n",
    "        dummies=sdummies_id, \n",
    "        col_id='id', \n",
    "        col_look='sales', \n",
    "        look_back=LOOK_BACK, \n",
    "        look_fwd=LOOK_FWD, \n",
    "        cols_features=cols_features\n",
    "    )\n",
    "    preds = model.predict(X_pred)\n",
    "    spred.loc[\n",
    "        (spred.id == pred_id) & \n",
    "        (spred.d_ > 1913) & \n",
    "        (spred.d_ <= 1913 + 28), \n",
    "        'sales'\n",
    "    ] = upscale(preds[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_id =  np.random.choice(spred.id.unique())\n",
    "spred_plt = spred.loc[spred.id == pred_id, ['d_', 'sales']].set_index('d_')\n",
    "spred_plt.loc[spred_plt.index <= 1913, 'sales'] = upscale(spred_plt[spred_plt.index <= 1913]['sales'])\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.plot(spred_plt[spred_plt.index <= 1913], label='fact')\n",
    "plt.plot(spred_plt[spred_plt.index > 1913], label='pred')\n",
    "plt.title(pred_id)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spred_subm = spred.loc[spred.d_ > 1913, ['id', 'd_', 'sales']].copy()\n",
    "spred_subm['d_'] = spred_subm['d_'].apply(lambda x: 'F{}'.format(x - 1913))\n",
    "spred_subm.loc[spred_subm['sales'] < 0, 'sales'] = 0\n",
    "spred_subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_cols = ['F{}'.format(x) for x in range(1, 28 + 1)]\n",
    "spred_subm = spred_subm.set_index(['id', 'd_']).unstack()['sales'][f_cols].reset_index()\n",
    "spred_subm.fillna(0, inplace=True)\n",
    "spred_subm.sort_values('id', inplace=True)\n",
    "spred_subm.reset_index(drop=True, inplace=True)\n",
    "spred_subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spred_subm_eval = spred_subm.copy()\n",
    "spred_subm_eval['id'] = spred_subm_eval['id'].str.replace('validation', 'evaluation')\n",
    "spred_subm = pd.concat([spred_subm, spred_subm_eval], axis=0, sort=False)\n",
    "print(spred_subm.shape)\n",
    "spred_subm.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Orange Python 3",
   "language": "python",
   "name": "orange"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
