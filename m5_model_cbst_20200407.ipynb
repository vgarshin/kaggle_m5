{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "pd.set_option('display.max_columns', None)\n",
    "print('available GPU devices:', len(os.environ['CUDA_VISIBLE_DEVICES']), \n",
    "      ' | device num:', os.environ['CUDA_VISIBLE_DEVICES'])\n",
    "from catboost.utils import get_gpu_device_count\n",
    "from tqdm.notebook import tqdm\n",
    "print('available GPU devices catboost:', get_gpu_device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data'\n",
    "MODELS_DIR = './models'\n",
    "MODEL_VER = 'v0'\n",
    "BACKWARD_LAGS = 60\n",
    "CUT_DATE = '2014-01-01'\n",
    "VAL_DATE = '2016-04-01'\n",
    "END_DATE = '2016-04-24'\n",
    "print(datetime.strptime(END_DATE, '%Y-%m-%d'))\n",
    "#-----|CUT_DATE|---train---|VAL_DATE|--val--|END_DATE|--forecast +28 days-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CALENDAR_DTYPES = {\n",
    "    'date':             'str',\n",
    "    'wm_yr_wk':         'int16', \n",
    "    'weekday':          'object',\n",
    "    'wday':             'int16', \n",
    "    'month':            'int16', \n",
    "    'year':             'int16', \n",
    "    'd':                'object',\n",
    "    'event_name_1':     'object',\n",
    "    'event_type_1':     'object',\n",
    "    'event_name_2':     'object',\n",
    "    'event_type_2':     'object',\n",
    "    'snap_CA':          'int16', \n",
    "    'snap_TX':          'int16', \n",
    "    'snap_WI':          'int16'\n",
    "}\n",
    "PARSE_DATES = ['date']\n",
    "SPRICES_DTYPES = {\n",
    "    'store_id':    'object', \n",
    "    'item_id':     'object', \n",
    "    'wm_yr_wk':    'int16',  \n",
    "    'sell_price':  'float32'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(is_train=True, backward_lags=None):\n",
    "    strain = pd.read_csv('{}/sales_train_validation.csv'.format(DATA_DIR))\n",
    "    print('read train:', strain.shape)\n",
    "    cat_cols = ['id', 'item_id', 'dept_id','store_id', 'cat_id', 'state_id']\n",
    "    last_day = int(strain.columns[-1].replace('d_', ''))\n",
    "    print('last day is:', last_day)\n",
    "    if not is_train:\n",
    "        for day in range(last_day + 1, last_day + 28 + 28 + 1):\n",
    "            strain['d_{}'.format(day)] = np.nan\n",
    "    strain = pd.melt(\n",
    "        strain,\n",
    "        id_vars = cat_cols,\n",
    "        value_vars = [col for col in strain.columns if col.startswith('d_')],\n",
    "        var_name = 'd',\n",
    "        value_name = 'sales'\n",
    "    )\n",
    "    print('melted train:', strain.shape)\n",
    "    calendar = pd.read_csv('{}/calendar.csv'.format(DATA_DIR), dtype=CALENDAR_DTYPES, parse_dates=PARSE_DATES)\n",
    "    print('read calendar:', calendar.shape)\n",
    "    strain = strain.merge(calendar, on='d', copy=False)\n",
    "    print('calendar merge done')\n",
    "    sprices = pd.read_csv('{}/sell_prices.csv'.format(DATA_DIR), dtype=SPRICES_DTYPES)\n",
    "    print('read prices:', sprices.shape)\n",
    "    strain = strain.merge(\n",
    "        sprices, \n",
    "        on=['store_id', 'item_id', 'wm_yr_wk'], \n",
    "        copy=False\n",
    "    )\n",
    "    print('prices merge done')\n",
    "    print('begin train date:', strain['date'].min())\n",
    "    print('end train date:', strain['date'].max())\n",
    "    if not is_train:\n",
    "        strain = strain.loc[\n",
    "            strain['date'] >= (datetime.strptime(END_DATE, '%Y-%m-%d') - timedelta(days=backward_lags))\n",
    "        ]\n",
    "    else:\n",
    "        strain = strain.loc[strain['date'] >= CUT_DATE]\n",
    "    print('date cut train:', strain.shape)\n",
    "    print('cut train date:', strain['date'].min())\n",
    "    print('end train date:', strain['date'].max())\n",
    "    return strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(strain):\n",
    "    print('in dataframe:', strain.shape)\n",
    "    lags = [7, 28]\n",
    "    windows= [7, 28]\n",
    "    wnd_feats = [\n",
    "        'id', \n",
    "        'item_id', \n",
    "        #'dept_id', \n",
    "        'store_id', \n",
    "        'cat_id', \n",
    "        #'state_id'\n",
    "    ]\n",
    "    lag_cols = ['lag_{}'.format(lag) for lag in lags ]\n",
    "    for lag, lag_col in zip(lags, lag_cols):\n",
    "        strain[lag_col] = strain[['id', 'sales']].groupby('id')['sales'].shift(lag)\n",
    "    print('lag sales done')\n",
    "    for wnd_feat in wnd_feats:\n",
    "        for wnd in windows:\n",
    "            for lag_col in lag_cols:\n",
    "                wnd_col = '{}_{}_rmean_{}'.format(lag_col, wnd_feat, wnd)\n",
    "                strain[wnd_col] = strain[[wnd_feat, lag_col]].groupby(wnd_feat)[lag_col].transform(\n",
    "                    lambda x: x.rolling(wnd).mean()\n",
    "                )\n",
    "        print('rolling mean sales for feature done:', wnd_feat)\n",
    "    date_features = {\n",
    "        'week_num': 'weekofyear',\n",
    "        'quarter': 'quarter',\n",
    "        'mday': 'day'\n",
    "    }\n",
    "    for date_feat_name, date_feat_func in date_features.items():\n",
    "        strain[date_feat_name] = getattr(strain['date'].dt, date_feat_func).astype('int16')\n",
    "    print('date features done')\n",
    "    strain['d'] = strain['d'].apply(lambda x: int(x.replace('d_', '')))  \n",
    "    print('out dataframe:', strain.shape)\n",
    "    return strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "strain = get_df(is_train=True, backward_lags=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "strain = make_features(strain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_name = np.random.choice(strain['id'].unique())\n",
    "print('id to draw:', id_name)\n",
    "id_sales = strain.loc[strain['id'] == id_name].set_index('date')\n",
    "print('from', strain['date'].min(), 'to', strain['date'].max()) \n",
    "plt.figure(figsize=(18, 4))\n",
    "id_sales['sales'].plot(label='sales')\n",
    "id_sales['lag_7'].plot(label='lag_7')\n",
    "id_sales['lag_7_id_rmean_7'].plot(label='lag_7_id_rmean_7')\n",
    "try:\n",
    "    id_sales['lag_7_store_id_rmean_7'].plot(label='lag_7_store_id_rmean_7')\n",
    "    id_sales['lag_7_cat_id_rmean_7'].plot(label='lag_7_cat_id_rmean_7')\n",
    "except:\n",
    "    print('no features')\n",
    "    pass\n",
    "plt.title(id_name)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['id', 'sales', 'date', 'wm_yr_wk', 'weekday']\n",
    "train_cols = strain.columns[~strain.columns.isin(drop_cols)]\n",
    "cat_cols = [\n",
    "    'item_id', 'dept_id', 'store_id', 'cat_id', 'state_id', \n",
    "    #'year', 'wday', 'month', 'quarter',\n",
    "    'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2',\n",
    "    #'snap_CA', 'snap_TX', 'snap_WI'\n",
    "]\n",
    "strain[cat_cols] = strain[cat_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if False: #True if last period as validation\n",
    "    X_train = strain[strain['date'] <= VAL_DATE][train_cols]\n",
    "    y_train = strain[strain['date'] <= VAL_DATE]['sales']\n",
    "    X_val = strain[strain['date'] > VAL_DATE][train_cols]\n",
    "    y_val = strain[strain['date'] > VAL_DATE]['sales']\n",
    "else: #random sample for validation\n",
    "    val_size = int(strain.shape[0] * .15)\n",
    "    val_idxs = np.random.choice(strain.index.values, val_size, replace=False)\n",
    "    train_idxs = np.setdiff1d(strain.index.values, val_idxs)\n",
    "    X_train = strain.loc[train_idxs][train_cols]\n",
    "    y_train = strain.loc[train_idxs]['sales']\n",
    "    X_val = strain.loc[val_idxs][train_cols]\n",
    "    y_val = strain.loc[val_idxs]['sales']\n",
    "print('train shapes:', X_train.shape, len(y_train))\n",
    "print('val shapes:', X_val.shape, len(y_val))\n",
    "train_pool = Pool(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    cat_features=cat_cols\n",
    ")\n",
    "val_pool = Pool(\n",
    "    X_val, \n",
    "    y_val,\n",
    "    cat_features=cat_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, y_train, X_val, y_val, val_idxs, train_idxs, val_size\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(\n",
    "    iterations=1000,\n",
    "    task_type='GPU', #'CPU'\n",
    "    verbose=0,\n",
    "    loss_function='RMSE',\n",
    "    boosting_type='Plain',\n",
    "    depth=6,\n",
    "    gpu_cat_features_storage='CpuPinnedMemory',\n",
    "    #max_ctr_complexity=2\n",
    ")\n",
    "model.fit(\n",
    "    train_pool,\n",
    "    eval_set = val_pool,\n",
    "    plot=True   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('{}/model_{}.cbm'.format(MODELS_DIR, MODEL_VER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor().load_model('{}/model_{}.cbm'.format(MODELS_DIR, MODEL_VER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = sorted(\n",
    "    [(f, v) for f, v in zip(train_cols, model.get_feature_importance())],\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True\n",
    ")\n",
    "threshold = .25\n",
    "labels = [x[0] for x in feat_importances if x[1] > threshold]\n",
    "values = [x[1] for x in feat_importances if x[1] > threshold]\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "y_pos = np.arange(len(labels))\n",
    "ax.barh(y_pos, values)\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(labels)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('Performance')\n",
    "ax.set_title('feature importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spred = strain[strain['date'] >= VAL_DATE].copy()\n",
    "preds = model.predict(spred[train_cols])\n",
    "print('predictions done:', len(preds))\n",
    "spred.loc[:, 'sales'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_name = np.random.choice(strain['id'].unique())\n",
    "print('id to draw:', id_name)\n",
    "id_sales = strain.loc[(strain['id'] == id_name) & (strain['date'] >= VAL_DATE)].set_index('date')\n",
    "id_sales_pred = spred.loc[spred['id'] == id_name].set_index('date')\n",
    "print('from', strain['date'].min(), 'to', strain['date'].max()) \n",
    "plt.figure(figsize=(18, 4))\n",
    "id_sales['sales'].plot(label='sales')\n",
    "id_sales_pred['sales'].plot(label='sales prediction')\n",
    "plt.title(id_name)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "growth_rate = 1\n",
    "spred = get_df(is_train=False, backward_lags=BACKWARD_LAGS)\n",
    "for pred_day in tqdm(range(1, 28 + 28 + 1)):\n",
    "    pred_date = datetime.strptime(END_DATE, '%Y-%m-%d') + timedelta(days=pred_day)\n",
    "    pred_date_back = pred_date - timedelta(days=BACKWARD_LAGS + 1)\n",
    "    print('-' * 70)\n",
    "    print('forecast day forward:', pred_day, '| forecast date:', pred_date) \n",
    "    spred_data = spred[(spred['date'] >= pred_date_back) & (spred['date'] <= pred_date)].copy()\n",
    "    spred_data = make_features(spred_data)\n",
    "    spred_data = spred_data.loc[spred['date'] == pred_date, train_cols]\n",
    "    spred_data[cat_cols] = spred_data[cat_cols].fillna(0)\n",
    "    spred.loc[spred['date'] == pred_date, 'sales'] = growth_rate * model.predict(spred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_name = np.random.choice(strain['id'].unique())\n",
    "print('id to draw:', id_name)\n",
    "id_sales = strain.loc[(strain['id'] == id_name) & (strain['date'] >= VAL_DATE)].set_index('date')\n",
    "id_sales_pred = spred.loc[(spred['id'] == id_name) & (spred['date'] >= END_DATE)].set_index('date')\n",
    "print('from', strain['date'].min(), 'to', spred['date'].max()) \n",
    "plt.figure(figsize=(18, 4))\n",
    "id_sales['sales'].plot(label='sales')\n",
    "id_sales_pred['sales'].plot(label='sales prediction')\n",
    "plt.title(id_name)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spred_subm = spred.loc[spred['date'] > END_DATE, ['id', 'd', 'sales']].copy()\n",
    "last_d = int(spred.loc[spred['date'] == END_DATE, 'd'].unique()[0].replace('d_', ''))\n",
    "print('last d num:', last_d)\n",
    "spred_subm['d'] = spred_subm['d'].apply(lambda x: 'F{}'.format(int(x.replace('d_', '')) - last_d))\n",
    "spred_subm.loc[spred_subm['sales'] < 0, 'sales'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_cols = ['F{}'.format(x) for x in range(1, 28 + 28 + 1)]\n",
    "spred_subm = spred_subm.set_index(['id', 'd']).unstack()['sales'][f_cols].reset_index()\n",
    "spred_subm.fillna(0, inplace=True)\n",
    "spred_subm.sort_values('id', inplace=True)\n",
    "spred_subm.reset_index(drop=True, inplace=True)\n",
    "spred_subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_cols = ['F{}'.format(x) for x in range(1, 28 + 1)]\n",
    "f_cols_eval = ['F{}'.format(x) for x in range(28 + 1, 28 + 28 + 1)]\n",
    "spred_subm_eval = spred_subm.copy()\n",
    "spred_subm.drop(columns=f_cols_eval, inplace=True)\n",
    "spred_subm_eval.drop(columns=f_cols, inplace=True)\n",
    "spred_subm_eval.columns = spred_subm.columns\n",
    "spred_subm_eval['id'] = spred_subm_eval['id'].str.replace('validation', 'evaluation')\n",
    "spred_subm = pd.concat([spred_subm, spred_subm_eval], axis=0, sort=False)\n",
    "spred_subm.reset_index(drop=True, inplace=True)\n",
    "spred_subm.to_csv('submission.csv', index=False)\n",
    "print('submission saved:', spred_subm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
